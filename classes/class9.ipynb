{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 9 - 6.5.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and Test-Driven Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already met one widely adopted programming technique which isn't used as much in the academy - object-oriented programming. Another such technique, ubiquitously used wherever code is written _outside_ the academy, is testing. In my opinion, this is a crucial topic in software development that isn't treated with the respect it should in the academy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests are (usually) short pieces of code designed to assert that a small portion of your program does what you intend it to do. \n",
    "\n",
    "For example, if I have a class designed to perform calculations on some DataFrame that was created somewhere else, perhaps by adding some of its columns together, averaging them out and displaying the result, then I wish for my code to be correct and deterministic, in a sense that a single, defined input will always give the same correct output.\n",
    "\n",
    "This isn't trivial even for the most basic functions in Python. Let's try to build a \"wrapper\" over `np.tile`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
       "       [1, 2, 3, 1, 2, 3, 1, 2, 3]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A reminer of np.tile()\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "arr = np.array([1, 2, 3])\n",
    "tiled = np.tile(arr, (2, 3))  # repeat it twice in the row dimension (axis=0), \n",
    "                              # and three times in the column dimension\n",
    "tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our own implementation\n",
    "\n",
    "class Tiler:\n",
    "    \"\"\" Tile any number of objects on their first axis \"\"\"\n",
    "    def __init__(self, *args):\n",
    "        self.to_tile = args\n",
    "\n",
    "    def tile(self, reps=(1,)):\n",
    "        self.tiled = np.tile(self.to_tile, reps=reps)\n",
    "        return self.tiled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above class can tile as many array inputs as you wish, and currently it's just a fancy wrapper over `np.tile()`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "------\n",
      "[[1 2 3 1 2 3]\n",
      " [4 5 6 4 5 6]\n",
      " [1 2 3 1 2 3]\n",
      " [4 5 6 4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "tiled = Tiler([1, 2, 3], [4, 5, 6]).tile()\n",
    "print(tiled)\n",
    "\n",
    "print('------')\n",
    "tiled_again = Tiler([1, 2, 3], [4, 5, 6]).tile((2, 2))\n",
    "print(tiled_again)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a very simple implementation, with the only \"new\" thing being the `*args` argument to the `__init__` function. `*args` means: Pack into a tuple called `args` all non-keyword arguments that the function receives. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is 1\n",
      "b is 2\n",
      "The rest of the data received is (3, 4, 'a')\n"
     ]
    }
   ],
   "source": [
    "def f(a, b, *args):\n",
    "    print(f\"a is {a}\")\n",
    "    print(f\"b is {b}\")\n",
    "    print(f\"The rest of the data received is {args}\")\n",
    "    \n",
    "f(1, 2, 3, 4, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `*args` when we wish to write a function with a non-constant number of arguments. The \"magic\" is done with the star (`*`), the `args` is just a convention, it's not a keyword. The star knows to bind the inputs into a tuple. In our case, we wish the `Tiler` class to tile as many arrays as the user wishes. This is most easily done with the `*args` parameter. Like `*args`, Python also has `**kwargs` that binds the keyword argument inputs into a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we understand the class completely - does it work?\n",
    "\n",
    "It does work, but it's not _guaranteed_ to work. Some issues are clear and can be solved immediately, like some basic type-checking that we should implement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tiler:\n",
    "    \"\"\" \n",
    "    Tile any number of objects on their first axis.\n",
    "    Returns: np.ndarray tiled across the first dimension.\n",
    "    Errors: TypeError if supplied with invalid iterables\n",
    "    \"\"\"\n",
    "    def __init__(self, *args):\n",
    "        _to_tile = self._verify_inp(args)\n",
    "        self.to_tile = _to_tile\n",
    "\n",
    "    def tile(self, reps=(1,)):\n",
    "        self.tiled = np.tile(self.to_tile, reps=reps)\n",
    "        return self.tiled\n",
    "    \n",
    "    def _verify_inp(self, it):\n",
    "        to_tile = []\n",
    "        for item in it:\n",
    "            if not isinstance(item, (list, np.ndarray)):\n",
    "                raise TypeError(f'Item {item} not a valid iterable to tile.')\n",
    "            to_tile.append(item)\n",
    "        return to_tile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the class specifies its return type and what happens in case of an error. A good application will know to wrap the use of the class in a `try... except` block and catch any `TypeError`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "--------\n",
      "TypeError: Item {4, 5, 6} not a valid iterable to tile.\n"
     ]
    }
   ],
   "source": [
    "# This works:\n",
    "try:\n",
    "    tiled = Tiler([1, 2, 3], [4, 5, 6]).tile()\n",
    "except TypeError as e:\n",
    "    print(f\"TypeError: {e}\")\n",
    "print(tiled)\n",
    "\n",
    "# This shouldn't\n",
    "print(\"--------\")\n",
    "try:\n",
    "    tiled_wrong = Tiler([1, 2, 3], {4, 5, 6}).tile()  # input is a set, not a list\n",
    "except TypeError as e:\n",
    "    print(f\"TypeError: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are we covered? Is this class no longer vulnerable to any type of non-legitimate input? Of course it is vulnerable, and some of us might already see a few corner cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([]), array([1, 2, 3])], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    tiled = Tiler([], np.array([1, 2, 3])).tile()\n",
    "except TypeError as e:\n",
    "    print(f\"TypeError: {e}\")\n",
    "\n",
    "tiled  # what is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This array of lists and arrays is certainly not what we had in mind when tiling an empty list an a simple array. We can think what exactly we expect this function to do, but this output will certainly not be on the list of possible outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I really don't have to convince you that software, even the most basic application, has bugs. But _thinking_ that we solved our bugs by the insertion of methods like `self._verify_inp` doesn't mean we actually solved them.\n",
    "\n",
    "To this end we write tests for our program. You've already seen unit tests in your homework assignments. You were asked to make sure that your solution passes all tests before submitting. This exemplifies a way through which we can be more certain that our program does what we thought it was doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests are important to us for two reasons. The first one is that even simple programs are more complicated than we think. The `Tiler` class is a good example, but you might imagine that as soon as we add interfaces between classes, methods and functions, things might get a bit messy. For example, in the aviation industry, for each line of code a software has, you may find about 8 lines dedicated to testing it.\n",
    "\n",
    "Moreover, when we deal with user input - data files, parameters for script - we should expect the unexpected, even if the main user is ourselves. Our future self in a few months will probably not remember the type of every parameter it has to enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second reason is Python's dynamic nature, or _duck-typing._ If you want to enforce a function to only accept inputs of a single type, _you_ must be the one writing these assertions, either outside or inside the function. For example, a function that adds two numbers needs a `isinstance(value, (int, float))` somewhere near its top to avoid these mistakes. Statically-typed languages, like C, define a type for each variable. A function adding two integers simply cannot accept a non-integer input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's dynamic nature is a blessing on many occasions, but it can sometimes be a real pain. This nature is the second important reason to write tests to our code. Many cases that in other programming languages would've resulted in a simple `TypeError`, can cause major bugs in Python due to wrong input types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Driven Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test-Driven Development, or TDD, is a very popular way to solve the problems we described. In TDD we reverse the process of writing code. We first write a test to the function we wish to write. It fails - because the function doesn't exist yet - and then we write then function until we're passing our test. We then add more tests to make sure that the function works properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume I wish to write a function that adds two positive integers. First I'll write a few basic tests for the function, and then I'll try to run them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test functions always start with \"test_...\"\n",
    "def test_basic_addition():\n",
    "    first = 2\n",
    "    second = 4\n",
    "    result = 6\n",
    "    return intadd(first, second) == result\n",
    "    \n",
    "def test_negative_inp1():\n",
    "    try:\n",
    "        result = intadd(-1, 1)\n",
    "    except TypeError:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def test_negative_inp2():\n",
    "    try:\n",
    "        result = intadd(1, -1)\n",
    "    except TypeError:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the tests are written (and are failing, since the fucntion `intadd` doesn't exist, we need to write the function so that it will comply with the tests we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intadd(num1, num2):\n",
    "    \"\"\" Non-negative integer addition \"\"\"\n",
    "    if (num1 < 0) or (num2 < 0):\n",
    "        raise TypeError('Input must be positive.')\n",
    "    return num1 + num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(test_basic_addition())\n",
    "print(test_negative_inp1())\n",
    "print(test_negative_inp2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function works! See how each test deals with a unique sub-case of failure? It's much easier to debug and answer \"what went wrong?\" when you tests are so precise. A good tests consists of a couple of lines of initialization, a couple of lines that call the tested function, and the `assert`ing line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the time it took me to write the implementation, I thought of a different edge case - floating point numbers input. Now I should write tests that will check this input type, they will fail - and then I can refactor my `intadd` function to deal with these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_float_inp():\n",
    "    \"\"\" A shorter version - check both inputs in a single test function \"\"\"\n",
    "    try:\n",
    "        result = intadd(1., 2)\n",
    "        result = intadd(2, 1.)\n",
    "    except TypeError:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(test_float_inp())  # False!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intadd(num1, num2):\n",
    "    \"\"\" Non-negative integer addition \"\"\"\n",
    "    if (num1 < 0) or (num2 < 0):\n",
    "        raise TypeError('Input must be positive.')\n",
    "    if isinstance(num1, float) or isinstance(num2, float):\n",
    "        raise TypeError('Input must be integer.')\n",
    "    return num1 + num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(test_float_inp())  # True!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the process continues - every time I think of more edge cases, I write failing tests and then refactor my own function.\n",
    "\n",
    "Another important thing to note here is the way TDD forces me to \"design the API\" of my function. As you can see, when I wrote the test I had to think of the output I'll receive when I enter wrong inputs. In this case I thought it was most appropriate for the function to return an TypeError - an exception that if not caught can terminate the execution of my application. This appeared to be the right choice here, but sometimes we can define a different result for faulty inputs. We could've returned `-1` if the input was invalid, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With TDD, most people don't actually write the first tests before they write the function. TDD purists might insist on that, but for all intents and purposes, if you keep the development of the tests very closely tied to the development of the function itself - you're doing TDD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual usage - `pytest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have guessed, the Python ecosystem offers tools to automate the testing process. The standard library comes with a `unittest` module, and another famous one is `nosetests`. But the most popular (and advanced) library as of early 2018 is [`pytest`](https://docs.pytest.org/en/latest/), and that will be the our library of choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `tests_demo` folder you can see how one structures the tests a project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating this file structure, you just call `pytest` in the command line after you `cd`ed into the folder containing the project - and all tests are run for you.\n",
    "\n",
    "`pytest` has some advanced features. In the tests inside `tests_demo` you could already see the `parametrize` decorator, used to call the same test with several different inputs. `pytest` is smart enough to tell us which input out of the ones we entered caused the exception. In addition, you can also mark some tests as \"expected to fail\". Finally, It can also create automatic tests for you. [Here](https://docs.pytest.org/en/latest/parametrize.html#basic-pytest-generate-tests-example) you'll find the formal docs, and [here](https://hackebrot.github.io/pytest-tricks/create_tests_via_parametrization/) you can find a clear blog post explaining it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A few extra points:\n",
    "\n",
    "1. Tests should be as concise as possible. Their execution time should be minimal.\n",
    "2. Run your test suit as often as possible. Minimal frequency is before each commit you make.\n",
    "3. You should try hard to translate bugs into tests. These might be the most important tests you'll write.\n",
    "4. Test names are long. It's fine - it's because we don't use docstrings for tests.\n",
    "5. You can configure PyCharm to work with `pytest` in _File - Settings - Tools - Python Integrated Tools - Default test runner: py.test._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unit tests repeatedly tests functions or methods your write under different inputs, and are the backbone of any reliable test suit. However, unit tests are not enough, since they don't check the interface between the different functions and classes in your application.\n",
    "\n",
    "Integration tests are larger, heavier tests that take at least two components, or units, of your application, and makes sure that they interact well with each other.\n",
    "\n",
    "Obviously, if we start taking each two consecutive functions and write an integration test for that pair, and then continue with all three consecutive functions and write these integration tests, and so on - we'll never finish writing the damn application. That's why integration testing is used at crucial junctions of our application, between major classes for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a class that returns the difference between the Fibonacci series and the prime numbers series, up to some _n._ The output should be an array of numbers, n-items long, and a plot to accompany it. As an example, for $n=3$, I expect the array to be `np.array([-2, -2, -4])`. Write the class in a test-driven development style.\n",
    "\n",
    "A reminder, the Fibonacci series is a series of numbers starting from (0, 1), with its next element being the sum of the previous two numbers: 0, 1, 1, 2, 3, 5, ... Prime numbers start from 2 and are only divisible by themselves and 1 without a remainder.\n",
    "\n",
    "You decide on the class' interface and the details of implementation. You may use `numpy`, and I insist that you write at least 5 unit tests and 1 integration test for this class.\n",
    "\n",
    "Don't try to implement things in a performant way, with fancy algorithms. The focus here is the unit tests and test-driven development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise solutions are in the directory `fib_ser`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced and Performant Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the best things about Python is how easy it is to get started with. The syntax is clear, it has all the basic features, things work as you expect them to, and life is generally pleasant. But Python also supports very advanced features, which make coding with Python an enjoyable experience even after you think you've learned everything there is to know of the language.\n",
    "\n",
    "While technically you can write good Python code without using these features - it's sometimes a real shame not to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a simple sense, perhaps simplistic, generators are iterators. Meaning, a generator is always an object you can iterate over. In Python you can iterate over most data structures, including dictionaries, lists, tuples and more - and so in this sense generators are similar. However, when we iterate over a list, for example, we're iterating over an existing data structures with existing items. Likewise for dictionaries - when we iterate over them, we're \"handed\" with the dictionary's keys and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "a_list = [0, 10, 20]\n",
    "for item in a_list:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 0\n",
      "b 10\n",
      "c 20\n"
     ]
    }
   ],
   "source": [
    "a_dict = dict(a=0, b=10, c= 20)\n",
    "for key in a_dict:\n",
    "    print(key, a_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first major difference between a generator and the other iterators. A generator is a _recipe_ to create the next item in the chain. A generator is a piece of code telling the Python interpreter how to create the next item, but it doesn't hold this item in memory yet. A simple example might be a list containing values from 0 to 1000. A generator of this list will not have 1000 cells with their values - it would have instructions on the number of cells, and how to calculate the next value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already met a generator (well, kind of) - the `range()` function. When we tell Python to give us a range of number between 0 and 1000 by writing `range(1000)` - we're not actually generating the 1000 \"cells\" of values, but only the recipe. Let's see it in \"action\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 1000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(1000)  # a \"range\" object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 1000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = range(1000)\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(items)  # 48 bytes - not nearly enough to hold 1000 items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple 1000-element list isn't that heavy for a computer (but what about Arduinos?), but when lists get longer, with bigger arrays and massive data structures inside them, it's very inefficient to hold this amount of unused data in memory. \n",
    "\n",
    "Let's define our own generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_range(n):\n",
    "    \"\"\" Returns a list of items from 0 to n \"\"\"\n",
    "    num = 0\n",
    "    while num < n:\n",
    "        yield num\n",
    "        num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we create a generator, the code is executed until the first `yield` statement. This reserved keyword is what makes a function into a generator.\n",
    "\n",
    "When the code reaches the `yield` it holds, or \"saves\" its current state, until called by Python's `next()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-dd54763376f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_range = my_range(3)\n",
    "\n",
    "print(next(new_range))\n",
    "\n",
    "print(next(new_range))\n",
    "\n",
    "print(next(new_range))\n",
    "\n",
    "print(next(new_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time `next()` is used, the line with the `yield` is executed, and the function keeps going until it reaches  another `yield` statement. In the `my_range` function, while the index is smaller than `n` the code will reach a `yield`. When we don't satisfy this condition anymore, the code skips the loop and reaches the end of the function. This results in a special `StopIteration` exception, used only in these special cases. This means you can catch this exception and know that your generator went through all of its items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But calling `next()` multiple times isn't practical. Luckily, `for` loops implement this exact interface automatically, allowing us to use them instead of the tedious, repetitive `next()` calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "looprange = my_range(10)\n",
    "\n",
    "for item in looprange:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `for` loop is also smart enough to catch the `StopIteration` exception and terminate the loop, without raising any \"visible\" exceptions. A `for` loop is the common way to iterate over generators.\n",
    "\n",
    "Generators don't allow much besides it. You can't print them exactly, or index into them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object my_range at 0x0000020902FDA518>\n"
     ]
    }
   ],
   "source": [
    "range2 = my_range(10)\n",
    "print(range2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8792b66651eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrange2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "range2[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once used, generators are \"depleted\", you can't reuse them. This is a major difference between a generator and a list, for example - you're not limited by the number of times you can iterate over a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in looprange:\n",
    "    print(item)\n",
    "# Doesn't return anything, because we already depleted looprange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-4ffc473673f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlooprange\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# immediately raises StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(looprange)  # immediately raises StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to stress that all functions can become generators if they contain the `yield` statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def println():\n",
    "    print(\"Hello, \")\n",
    "    yield True\n",
    "    print(\"World\")\n",
    "    yield False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, \n",
      "True\n"
     ]
    }
   ],
   "source": [
    "gen2 = println()\n",
    "a = next(gen2)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "b = next(gen2)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to create generators is \"genexps\", or generator expressions, which are very similar to list comprehensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x000002097BBA6620>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = (2 * n for n in range(10))\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "for num in nums:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The round brackets tell the interpreter that we're creating a generator here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Write a generator function, or a piece of code including a generator, returning the `n` first Fibonacci numbers. The Fibonacci sequence starts with `1, 1` and the following item is always the addition of the last two items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise solution below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 3, 5, 8, 13, 21, 34, 55]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution with a single function\n",
    "def fib(n):\n",
    "    \"\"\" Returns the first n Fibonacci numbers \"\"\"\n",
    "    a, b = 1, 1\n",
    "    idx = 0\n",
    "    while idx < n:\n",
    "        yield a\n",
    "        a, b = b, a + b\n",
    "        idx += 1\n",
    "\n",
    "ten = fib(10)\n",
    "list(ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "8\n",
      "13\n",
      "21\n",
      "34\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "# Solution as a script\n",
    "def fibn():\n",
    "    \"\"\" Runs over all Fibonacci numbers \"\"\"\n",
    "    a, b = 1, 1\n",
    "    while True:\n",
    "        yield a\n",
    "        a, b = b, a + b\n",
    "        \n",
    "        \n",
    "gen = fibn()\n",
    "for i in range(10):\n",
    "    print(next(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nice thing about this implementation is that it's infinite - it contains, and can generate all Fibonacci numbers. We could never do that with lists and regular functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generators are used widely in the Python universe. `pathlib` uses them everywhere, for example. For our use-cases, which involve \"data-science\" stuff, it's usually less important. However, in one of my projects I have a large 5D array which I need to create. This array can easily weigh more than 1 GB RAM when I'm dealing with longer experiments. That's why I decided to write a generator function that creates and populates this array, `yield`ing 4D substacks of it over time. It reduces memory usage by at least two orders of magnitude, and allows my code to run faster on home machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decorators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decorators are functions that receive functions in their arguments. When you wrap an existing function with another function - you created a decorator. This feature is extensively used in web frameworks and in other important Python use cases, which means it has a special syntax: `@decorator`. Let's look at an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume I have a large data-processing pipeline script, built out of many smaller functions, which unfortunately takes a long time to run. I wish to understand _why_ it's taking so long, so I decide to add a printed statement at the start and end of each function, so that I could see with my eyes where the code \"hangs\". This is how I implemented it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_pipeline(fname):\n",
    "    data = load_data(fname)\n",
    "    processed = process_data(data)\n",
    "    appended = append_data(processed)\n",
    "    logged = log_data(appended)\n",
    "\n",
    "def load_data(fname):\n",
    "    print(\"Starting 'load_data'...\")\n",
    "    # ... Code ...\n",
    "    print(\"Ending 'load_data'...\")\n",
    "\n",
    "def process_data(data):\n",
    "    print(\"Starting 'process_data'...\")\n",
    "    # ... Code ...\n",
    "    print(\"Ending 'process_data'...\")\n",
    "    \n",
    "# And so on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is obviously very tedious. Even when I only have four functions, it's very repetitive and feels wrong. Moreover, it might have not solved my issue. My examination showed that all four functions take a considerable time to run, so I decide the profile the execution time of each function, to better understand which function is the most costly and optimize it first.\n",
    "\n",
    "Here's how I redefined all functions to measure their execution time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def load_data(fname):\n",
    "    print(\"Starting 'load_data'...\")\n",
    "    start_time = time.time()\n",
    "    # ... Code ...\n",
    "    print(f\"It took the code {time.time() - start_time} milliseconds to run.\")\n",
    "    print(\"Ending 'load_data'...\")\n",
    "\n",
    "def process_data(data):\n",
    "    print(\"Starting 'process_data'...\")\n",
    "    start_time = time.time()\n",
    "    # ... Code ...\n",
    "    print(f\"It took the code {time.time() - start_time} milliseconds to run.\")\n",
    "    print(\"Ending 'process_data'...\")\n",
    "    \n",
    "# And so on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works, but again - it's very repetitive. Also, if I decide that I want to see the execution time in seconds, and not milliseconds, I have to go through each function and re-implement it. Very tedious. \n",
    "\n",
    "The solutions is to _decorate_ the function with a `printer` and `timer` functions, that do this job exactly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printer(func):\n",
    "    def inner_func(argument):\n",
    "        print(f\"Starting {func.__name__}...\")\n",
    "        result = func(argument)\n",
    "        print(f\"Ending {func.__name__}...\")\n",
    "        return result\n",
    "    return inner_func      \n",
    "\n",
    "\n",
    "def timer(func):\n",
    "    def inner_func(argument):\n",
    "        start_time = time.time()\n",
    "        result = func(argument)\n",
    "        print(f\"It tooks the code {time.time() - start_time} milliseconds to run.\")\n",
    "        return result\n",
    "    return inner_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks complex at first, but it's really pretty simple. It uses the fact that functions in Python are objects, like any other element in the language. And because they're objects, they can be passed around as arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "def f(func):\n",
    "    \"\"\" Runs the func functions and prints 'hi' at the end \"\"\"\n",
    "    func()\n",
    "    print(\"hi\")\n",
    "    \n",
    "def print_hello():\n",
    "    print(\"hello\")\n",
    "    \n",
    "\n",
    "f(print_hello)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all objects, functions have attributes. Namely, they have the `__name__` attribute which contains... their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n",
      "print_hello\n"
     ]
    }
   ],
   "source": [
    "print(f.__name__)\n",
    "print(print_hello.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know we can pass functions as arguments to other functions. Let's try to examine the `printer` and `timer` functions again.\n",
    "\n",
    "They're both a function that receives a different, \"unknown\" function, as its argument. So far - so good. Then it defines another function which \"wraps\" the original function with some actions, like printing or timing. This inner function runs the original function and returns the result. In essence, it created a \"new implementation\" of that original function that does the exact same thing, but with the wrapping functionality (printing, timing, etc.). This new function (`inner_func`) can replace any instance of the original function without any troubles, since in essence it just calls it. It's adds a couple of statements before and after that call, but the essential functionality remained unchanged.\n",
    "\n",
    "Lastly, the outer function, which we call the decorator, returns the inner function as its return value. So this function receives a function as its argument and return a new, improved function as its output. To use it, we just \"rename\" the existing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_printer = printer(load_data)\n",
    "load_data_timed = timer(load_data)\n",
    "\n",
    "process_data_printer = printer(process_data)\n",
    "process_data_timed = timer(process_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obviously use this `timer` function on any function we wish to time. When we wish to time functions in seconds, rather than milliseconds, we'll just change this one instance of `timer` and be done with it, and likewise for `printer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only small caveat here is the fact that we currently require the function we're replacing to have a single `argument` as its argument. This implementation detail is small but very impactful - it means that our decorator will only decorate successfully functions that have a single argument. To remedy this we'll have to use `*args` and `**kwargs`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detour - `*args`, `**kwargs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You use `*args` and `*kwargs` when you're not sure how many arguments are used for a function. Actually, the syntax is only `*` and `**` - the words `args` and `kwargs` are used by convention. `args` is obviously arguments, or unnamed arguments given to a function. `kwargs` is keyword arguments, or arguments given as `key=value`. Let's see a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(required_argument, *args, **kwargs):\n",
    "    print(required_argument)\n",
    "    if args:\n",
    "        print(args)\n",
    "    \n",
    "    if kwargs:\n",
    "        for key, value in kwargs.items():\n",
    "            print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "f() missing 1 required positional argument: 'required_argument'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-06d6587ee42e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# doesn't work - we have one required argument to the function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: f() missing 1 required positional argument: 'required_argument'"
     ]
    }
   ],
   "source": [
    "f()  # doesn't work - we have one required argument to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required\n"
     ]
    }
   ],
   "source": [
    "f('required')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required\n",
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "f('required', 1, 2, 3)  # the second printed row is the args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required\n",
      "(1, 2, 3)\n",
      "kw1 a\n",
      "kw2 b\n"
     ]
    }
   ],
   "source": [
    "f('required', 1, 2, 3, kw1='a', kw2='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `args` is a tuple containing all unnamed parameters that were given to the function, in the order they were given.\n",
    "\n",
    "`kwargs` is a dictionary, its keys being the keywords, and values - the given values. Here's another short example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 20\n"
     ]
    }
   ],
   "source": [
    "def f(a=1, b=2):\n",
    "    print(a, b)\n",
    "\n",
    "inputs = {'a': 10, 'b': 20}\n",
    "f(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see here is that the function's signature doesn't have to contain `*args` or `**kwargs`. The `**` operator \"opens up\" the input dictionary, allowing the `f()` function to use the parameters without any issues. This is how we're going to use it for our decorators - we'll redefine them as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printer(func):\n",
    "    def inner_func(*args, **kwargs):\n",
    "        print(f\"Starting {func.__name__}...\")\n",
    "        result = func(*args, **kwargs)\n",
    "        print(f\"Ending {func.__name__}...\")\n",
    "        return result\n",
    "    return inner_func      \n",
    "\n",
    "\n",
    "def timer(func):\n",
    "    def inner_func(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        print(f\"It tooks the code {time.time() - start_time} milliseconds to run.\")\n",
    "        return result\n",
    "    return inner_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now be sure that our functions will always run regardless the number of inputs given to them. This makes us happy - but not completely happy. We still have to redefine all functions as we've seen before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_printer = printer(load_data)\n",
    "load_data_timed = timer(load_data)\n",
    "\n",
    "process_data_printer = printer(process_data)\n",
    "process_data_timed = timer(process_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It still requires us to rename all instances of these functions in all places of the code, and when we're done with the printing and timing - we have to rename them back.\n",
    "\n",
    "Why not \"rename\" the function back to its original name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = printer(load_data)\n",
    "process_data = timer(process_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This idiom is common enough to have a built-in language syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def load_data(fname):\n",
    "    # ... Code ...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use multiple decorators for functions as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@printer\n",
    "@timer\n",
    "def process_data(data):\n",
    "    # ... Code ...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we wish to stop printing and timing our function, we simply delete this decorator in the relevant places.\n",
    "\n",
    "Decorators allow more complex calls, like calling them with arguments, but we'll leave that topic for another day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `collections`, `itertools`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python standard library comes with many second-order tools that can make your life much easier. Many of the more useful ones are located in these two libraries - `collections` and `itertools`. Below I'll provide a brief tour of some of the more interesting features of these libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you want a tiny object with named fields, but without the hassle of creating a fully-fledged class, you actually wish to generate a namedtuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point(x=0, y=1)\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Point = namedtuple('Point', ['x', 'y'])\n",
    "p1 = Point(0, 0)\n",
    "p2 = Point(x=0, y=1)\n",
    "p3 = Point(1, y=2)\n",
    "\n",
    "print(p2)\n",
    "print(p3.y)\n",
    "print(p1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the data inside a `namedtuple` using either the positional index (`[0]`) or the name of that field (`x`). If all you wish to do is to a keep a small record of something, `namedtuple` is your best option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `defaultdict` is a dictionary that resorts to execute a predefined function if it doesn't find the key. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'three'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-d27b12743133>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtwo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'one'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'three'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'three'"
     ]
    }
   ],
   "source": [
    "d = dict(one=1, two=2)\n",
    "print(d['one'])\n",
    "print(d['three'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than a `KeyError`, a `defaultdict` would run a predefined function instead of raising this exception:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "d2 = defaultdict(list, one=1, two=2)\n",
    "print(d2['one'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when we call it with an unknown key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {'one': 1, 'three': [], 'two': 2})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2['three']\n",
    "d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It used the `list` \"factory\" to create a new list in that key. This is useful when sorting some key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {'blue': [2, 4], 'red': [1], 'yellow': [1, 3]})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)]\n",
    "d2 = defaultdict(list)\n",
    "for k, v in s:\n",
    "    d2[k].append(v)\n",
    "\n",
    "d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chained iterables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wish to iterate over several iterables together, we can use the following method from the `itertools` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "e\n",
      "f\n",
      "g\n",
      "-----\n",
      "[1, 2, 3, 4]\n",
      "[5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "chained = itertools.chain('abcd', 'efg')\n",
    "for letter in chained:\n",
    "    print(letter)\n",
    "\n",
    "print('-----')\n",
    "# Naive iteration over [[1, 2, 3, 4], [5, 6, 7, 8]] would result in two items - \n",
    "# two lists with four elements each:\n",
    "for item in [[1, 2, 3, 4], [5, 6, 7, 8]]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# We wish to iterate over the number themselves\n",
    "chained2 = itertools.chain.from_iterable([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "for letter in chained2:\n",
    "    print(letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `itertools` always creates generators from the items it receives as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'B'),\n",
       " ('A', 'C'),\n",
       " ('A', 'D'),\n",
       " ('B', 'A'),\n",
       " ('B', 'C'),\n",
       " ('B', 'D'),\n",
       " ('C', 'A'),\n",
       " ('C', 'B'),\n",
       " ('C', 'D'),\n",
       " ('D', 'A'),\n",
       " ('D', 'B'),\n",
       " ('D', 'C')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.permutations('ABCD', 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'B'), ('A', 'C'), ('A', 'D'), ('B', 'C'), ('B', 'D'), ('C', 'D')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.combinations('ABCD', 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to utilize parallel processing in Python. The easiest of all is multi-processing, i.e. the use of several CPU cores to run jobs in parallel. This is best used when each process is independent from the others, not having to share data between them. \n",
    "\n",
    "A typical use case is when we have a list or an `np.array` holding data, and we wish to perform the same computation on each element of that list. If this computation is truly independent, the `multiprocessing` module has some very easy-to-use solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def add_tuple(tup):\n",
    "    return tup[0] + tup[1]\n",
    "\n",
    "tups = [(0, 1), (2, 3), (4, 5), (6, 7)]\n",
    "pool = multiprocessing.Pool()  # can also enter the number of processes you wish to use\n",
    "result = pool.map(add_tuple, tups)\n",
    "result  # [1, 5, 9, 13]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above doesn't work in IPython and Jupyter due to some weird conflicts. Luckily, `ipyparallel` is an even better library which does the exact same thing and works everywhere.\n",
    "\n",
    "The Python script `multiprocess.py` located in this `Classes` folder contains a working copy of this script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threading is Python's weak point because of the GIL, and we'll not discuss it in this class. Another form of parallel processing is asynchronous programming, which we'll also not cover, but is actually one of Python's strongest points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numba` is a special library designed to speed-up Python's computation. In many cases it's comparable to `numpy` in terms of use cases, but it might be simpler for people without previous experience with arrays. We'll jump right into an example and then discuss some of the magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@jit\n",
    "def sum2d(arr):\n",
    "    M, N = arr.shape\n",
    "    result = 0.0\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            result += arr[i,j]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 ms  15.6 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n",
      "145 ms  6.47 ms per loop (mean  std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "arr = np.ones((10000, 10000))\n",
    "\n",
    "%timeit sum2d(arr)\n",
    "%timeit arr.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results up there are, for lack of a better word, amazing. Numpy has been optimized for ages, works in bare C, and is still slightly topped by `numba`, which seemingly just decorates a simple, perhaps _simplistic_, Python loop, making it amazingly fast.\n",
    "\n",
    "This magic happens with LLVM, an open-source project that aims at building a very fast, cross-language compiler. `numba` translates the code to LLVM-suitable code and lets LLVM optimize this code for it. The output is machine code which is fed into the processor directly, and somehow it's faster than all other solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba has more tricks in its sleeve. You can define the input types to squeeze it a bit more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, float64\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@jit(float64(float64[:, :]))\n",
    "def sum2d_inps(arr):\n",
    "    M, N = arr.shape\n",
    "    result = 0.0\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            result += arr[i,j]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 ms  10.4 ms per loop (mean  std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum2d_inps(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use parallel looping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, prange\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@jit([float64(float64[:, :])], parallel=True)\n",
    "def sum2d_p(arr):\n",
    "    M, N = arr.shape\n",
    "    result = np.float64(0.0)\n",
    "    for i in prange(M):\n",
    "        for j in prange(N):\n",
    "            result += arr[i,j]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.9 ms  2.63 ms per loop (mean  std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum2d_p(arr)  # pretty cool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When every bit of performance matters - `numba` might be the way to go. For very complicated functions that use fancy linear algebra algorithms, it might be the case that `numba` doesn't support these methods yet. In these occasions resort to basic `numpy` functions and wait till the `numba` developers implement that method - or do so yourself! `numba` is completely open-sourced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you wish to write performant code that utilizes significant parts of the standard library - niether `numpy` nor `numba` will help you. They require that you work with arrays, which are not as easy to work with as lists, for example. Dictionaries are also very helpful, but using them only with the standard Python interpreter will hinder you performance considerably.\n",
    "\n",
    "These are the cases where Cython shines. It allows you to write code with Python-like syntax and compile it ahead-of-time to a `myfile.c` source file, written in `C` automatically. When your code calls a function that was written in Cython, it will actually turn to the optimized `C` function and use that function instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated, Cython requires you to compile your code before running the parent Python script. To do that, you have to create a `setup.py` file that tells the Cython compiler where to find the files in question.\n",
    "\n",
    "A Cython file ends with `X.pyx`, so `setup.py` should point there. Here's a basic example of `setup.py`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from distutils.core import setup\n",
    "from Cython.Build import cythonize\n",
    "\n",
    "setup(\n",
    "    ext_modules = cythonize('my_file.pyx'),\n",
    "    # other setup.py options come here\n",
    ")\n",
    "```\n",
    "\n",
    "Then you navigate with your command line to the folder containing `setup.py` and write `python setup.py build_ext --inplace`, which tells Cython to \"build\", i.e. compile, the code in the `.pyx` file and add it `inplace`, i.e. to this directory.\n",
    "\n",
    "An example can be found in the `cython_demo` folder. Let's see it here in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cython_demo import plain_python, primes_cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_python.primes_python(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primes_cython.primes(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.5 ms  3.47 ms per loop (mean  std. dev. of 7 runs, 10 loops each)\n",
      "2.95 ms  635 s per loop (mean  std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit plain_python.primes_python(1000)\n",
    "%timeit primes_cython.primes(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rands = np.random.random((1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 ms  793 s per loop (mean  std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rands[rands < 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit([float64[::1](float64[::1])], nopython=True, parallel=True)\n",
    "def filter_larger(rands):\n",
    "    arr = np.zeros_like(rands)\n",
    "    thresh = 0.5\n",
    "    last_idx = 0\n",
    "    for idx in prange(len(rands)):\n",
    "        if rands[idx] < 0.5:\n",
    "            arr[last_idx] = rands[idx]\n",
    "            last_idx += 1\n",
    "            \n",
    "    return arr[:last_idx]\n",
    "\n",
    "# The last_idx variable is probably hindering performance of the parallel loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 ms  789 s per loop (mean  std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit filter_larger(rands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cython_filter_demo import filter_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.3 ms  1.34 ms per loop (mean  std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit filter_array.filter_larger_cython(rands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun filter_array.filter_larger_cython(rands)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:general]",
   "language": "python",
   "name": "conda-env-general-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
